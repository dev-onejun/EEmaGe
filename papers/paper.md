# (Working Title) EEmaGe: EEG-based Image Generation for Visual Reconstruction

**Hypothesis**

1) Supervision is not required to construct the human's visual system.
2) Visual cues are ultimately discouraged from extracting the EEG features.

***Abstract***

**Version 1**
Visual reconstruction from EEG brain signals becomes possible with the advancement of AI. Recent researches showed that, in designed experiments, recorded EEG while presenting images enables ML models to reconstruct the images. Nevertheless, even though breakthroughs in AI have begun with imitating the human system, previous frameworks were not similar with the visual system. This research postulated that supervised learning should be avoided to build a reconstruction framework as well as visual cues ultimately keep away from the training to extract meaningful EEG features. The research proposes a novel framework called EEmaGe with *a self-supervised autoencoder and its downstream* to regenerate the human vision appropriately. *The framework showed the state-of-the-art performance in (cosine singularity) metrics. As the RE2I approach, the research is expected to contribute to solve the secret of the human brain which has not yet been solved.*

**Version 2**
Visual reconstruction from EEG has been paved with the advancement of AI. Recent studies have demonstrated the feasibility of reconstructing images from EEG recordings in designed experiments. Nevertheless, even though breakthroughs in AI have begun with imitating the human system, these frameworks lack resemblance to the visual system of the human. To address this challenge, this research proposes a novel framework called EEmaGe which utilizes self-supervised learning to reconstruct images from raw EEG data. Unlike supervised learning methods, which rely on labeled training data, the framework employs *a self-supervised autoencoder and downstream task* to mimic human vision without visual cues. *The experimental results showcase the state-of-the-art performance of the framework in metrics related to cosine singularity.
As the RE2I approach, the research has the potential to contribute to advance our knowledge of the intricacies of the human brain and to develop more sophisticated AI systems that effectively mock human visual perception.*

**Acronym/Abbreviation**
* electroencephalogram?/electroencephalography? (EEG)
* Artificial Intelligence (AI)
* Machine Learning (ML)
* Reconstruction from EEG to Image (RE2I)
* Convolutional Neural Networks (CNN)
* Small-World Neural Networks (SWNet)
* Generative Adversarial Networks (GANs)
* Brain-Computer Interface (BCI)

**Keywords**
* Parallel Gradient Descent
    - Conduct gradient descent while feed-forwarding to decrease the consumed training time.

## I. Introduction

**WHY IS SUPERVISION NOT REQUIRED TO CONSTRUCT HUMAN VISUAL SYSTEM?**
It is a fact that things always exist regardless of someone's perception. This influenced that the definitions of looking, seeing, and watching are different. Looking is to toward eyes somewhere, seeing is to perceive things what eyes direct, and watching is to spend time and pay attention to the things [4]. In other words, 'looking' belongs to the 'seeing' set and 'seeing' belongs to the 'watching' set. The visual system of humans performs looking, meaning that, supervision is not required to imitate the system. **IS VISUAL RECONSTRUCTION TASK SAME AS LOOKING(-VISUAL SYSTEM)?**

BCI, firstly proposed by Vidal [10], has seeked to the key of the human brain where the area has yet been conquered. Disabled people are expected to be benefited to live real lives with others, if BCI researches continuously evolve. Among the methodlogies of BCIs, EEG analysis has especially been drawn attention due to its advantages, non-invasive and cost-effectie sensors which are utilized during brain measurements. The analysis, which uses a signal recorded electrical activities of brains [5], is pervasively adopted in medical and research areas to diagnose brain diseases. Even though its effectiveness in those areas, EEG required manual analysis of experts like physicians and researchers [11].

Recently, many researches founded that EEG is able to reproduce visual experiences.

For instance, shedding a light on generating images from feature vectors with GANs, the networks were employed to generate images from EEG signals [6, 8, 9].

"Electroencephalography is a medical imaging technique that reads scalp electrical activity generated by brain structures. The electroencephalogram is defined as electrical activity of an alternating type recorded from the scalp surface after being picked up by metal electrodes and conductive media."

AI has been adnvaced with imitating the system of human beings. For instance, Neural Network [1] mimicked the human nervous system as well as its advancement like CNN [2] and SWNet [3] (imitate/mimic/resemble).

## II. Related Works

Palazzo et al [6] firstly founded that visual experience can be generated from EEG signals. The research recorded the signals while presenting the ImageNet [7] dataset to subjects. Although the research firstly founded that visual experience can be generated from EEG signals, the proposed method were limited to the dataset category since it relied on supervised learning.
NeuroVision

## III. Experiment

**A. EEmaGe**

**WHY DID YOU MAKE THE MODEL LIKE THIS?**
In order to achieve the goals of the research which is the exclusion of the supervision in the reconstruction task, self-supervised learning is adopted to implement a model training. Autoencoder is a representative self-supervised learning method hinged on neural net architectures.

EEmaGe is an autoencoder-based model architecture which gets an input (*e*, *i*) pair where *e* is an EEG and *i* is an image. The pair is shuffled from its own pair matched by original datasets. (***or make all possible pairs to maximize the number of the data*** ) Two autoencoders which their encoders share weights with each others comprise the architecture.

**B. Downstream Tasks**

In this research, a downstream task is defined as reconstructing images from EEG signals with an autoencoder. The autoencoder is made up of the EEG encoder and the image decoder from EEmaGe. Inferences of the autoencoder solely implement to make the images.

***WHICH METRICS IS SUITTED TO ASSESS THIS TASK?***
The output images are compared by ***cosine singularity (IT'S IMPOSSIBLE)*** with the original images.

## IV. Implementation

**A. Environments**

PyTorch 2.
loss function - mse
***WHY DID YOU CHOOSE MSE AS LOSS FUNCTION*** (https://www.sciencedirect.com/science/article/pii/S0141029624001329 need more compelling resources)

## V. Conclusion

## References

* [1] McCulloch, Warren S., and Walter Pitts. "A logical calculus of the ideas immanent in nervous activity." The bulletin of mathematical biophysics 5 (1943): 115-133. [MLA]
* [2] Fukushima, Kunihiko. "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position." Biological cybernetics 36.4 (1980): 193-202. [MLA]
* [3] Javaheripi, Mojan, Bita Darvish Rouhani, and Farinaz Koushanfar. "SWNet: Small-world neural networks and rapid convergence." arXiv preprint arXiv:1904.04862 (2019). [MLA]
* [4] https://www.britannica.com/dictionary/eb/qa/see-look-watch-hear-and-listen , accessed in Mar 4 2024. []
* [5] Teplan, Michal. "Fundamentals of EEG measurement." Measurement science review 2.2 (2002): 1-11. [MLA]
* [6] Palazzo, Simone, et al. "Generative adversarial networks conditioned by brain signals." Proceedings of the IEEE international conference on computer vision. 2017. [MLA]
* [7] J. Deng, W. Dong, R. Socher, L. -J. Li, Kai Li and Li Fei-Fei, "ImageNet: A large-scale hierarchical image database," 2009 IEEE Conference on Computer Vision and Pattern Recognition, Miami, FL, USA, 2009, pp. 248-255, doi: 10.1109/CVPR.2009.5206848. [IEEE]
* [8] Khare, Sanchita, et al. "NeuroVision: perceived image regeneration using cProGAN." Neural Computing and Applications 34.8 (2022): 5979-5991. [MLA]
* [9] P. Singh, P. Pandey, K. Miyapuram and S. Raman, "EEG2IMAGE: Image Reconstruction from EEG Brain Signals," ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Rhodes Island, Greece, 2023, pp. 1-5, doi: 10.1109/ICASSP49357.2023.10096587. [IEEE]
* [10] Vidal, Jacques J. "Toward direct brain-computer communication." Annual review of Biophysics and Bioengineering 2.1 (1973): 157-180. [MLA]
* [11] https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/overview , accessed in Mar 4 2024. []
